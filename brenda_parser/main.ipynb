{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'D:\\\\Python\\\\2021-Brenda and rhea Database\\\\others\\\\'\n",
    "paths = {\n",
    "    \"file\": PATH + \"brenda_download.txt\", # the TXTFile.\n",
    "    \"NAME\": PATH + \"NAME.txt\", # The Name file.\n",
    "    \"results\": PATH + \"results\", # to store results.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = brenda_parser(txtfile = paths[\"file\"], namefile = paths[\"NAME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the ECs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.0.0.0', '1.1.1.1', '1.1.1.10', '1.1.1.100', '1.1.1.101')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.getECs()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7558"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp.getECs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get names of records (raw records) that were extracted but not processed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PROTEIN', 'RECOMMENDED_NAME', 'SYSTEMATIC_NAME', 'SYNONYMS')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.getRawNames()[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Alip1p <154>',\n",
       " ' LipY <136>',\n",
       " '#1,7,9,14,21,26,34,43,47,85,90,93,104,106,135,150# triacylglycerol acylhydrolase <111,122,189,193,208,209,218,238,264,266,315,316,320,331,332,348>',\n",
       " '#1,9# TPL <315,348>',\n",
       " '#10# Tgl4p <135>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.getRawRecords('3.1.1.3', 'SYNONYMS')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get names of records (handled records) that were extracted and processed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PROTEIN', 'REFERENCE', 'RECOMMENDED_NAME', 'REACTION', 'SYSTEMATIC_NAME')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.getHandledNames()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('21',\n",
       " 'Pseudomonas aeruginosa  ',\n",
       " None,\n",
       " '24,57,66,106,111,115,123,139,140,141,144,147,168,181,196,197,201,210 214,245,269,293')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.getHandledRecords('3.1.1.3', 'PROTEIN')[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class brenda_parser():\n",
    "    def __init__(self, txtfile = paths[\"file\"], namefile = paths[\"NAME\"]):\n",
    "        self._pages = dict()\n",
    "        \n",
    "        # 5 types of RE patterns.\n",
    "        self.RE_patterns = {'PROTEIN': '#([\\d]+)# (.+?)(?:\\((?=#)(.+?)(?<=>)\\))? <([\\d, ]+)>',\n",
    "                            'REFERENCE': '<([\\d]+)> (.+?) {Pubmed:[\\dn]*}(?: \\(c\\))?',\n",
    "                            }\n",
    "        for name in ['RECOMMENDED_NAME', 'REACTION', 'SYSTEMATIC_NAME', 'REACTION_TYPE', ]:\n",
    "            self.RE_patterns[name] = '(.*)'\n",
    "        for name in [ 'SYNONYMS',  'SOURCE_TISSUE',  'LOCALIZATION', 'NATURAL_SUBSTRATE_PRODUCT', 'SUBSTRATE_PRODUCT',\n",
    "                      'TURNOVER_NUMBER', 'KM_VALUE', 'PH_OPTIMUM', 'PH_RANGE', 'SPECIFIC_ACTIVITY', \n",
    "                      'TEMPERATURE_OPTIMUM', 'TEMPERATURE_RANGE', 'COFACTOR', 'ACTIVATING_COMPOUND', 'INHIBITORS', 'METALS_IONS',\n",
    "                      'MOLECULAR_WEIGHT', 'POSTTRANSLATIONAL_MODIFICATION', 'SUBUNITS', 'PI_VALUE',\n",
    "                      'APPLICATION', 'ENGINEERING', 'GENERAL_STABILITY', 'ORGANIC_SOLVENT_STABILITY',\n",
    "                      'OXIDATION_STABILITY', 'PH_STABILITY', 'STORAGE_STABILITY', 'TEMPERATURE_STABILITY', 'KI_VALUE',\n",
    "                      'IC50_VALUE', 'KCAT_KM_VALUE', 'EXPRESSION', 'GENERAL_INFORMATION']:\n",
    "            self.RE_patterns[name] = '#([\\d, ]+)# (.+?)(?: \\((?=#)(.+?)(?<=>)\\))?(?: \\|(?=#)(.+?)(?<=>)\\|)?(?: \\{.*?\\})? <([\\d, ]+)>'\n",
    "        for name in ['CLONED', 'CRYSTALLIZATION', 'PURIFICATION', 'RENATURED']:\n",
    "            self.RE_patterns[name] = \"#([\\d, ]+)# (.*)<([\\d, ]+)>\"\n",
    "        \n",
    "        self.register(txtfile, namefile)\n",
    "        self.parse()\n",
    "\n",
    "    ### API\n",
    "    def getECs(self,):\n",
    "        return tuple(self._pages.keys())\n",
    "    def getRawNames(self, ):\n",
    "        return tuple(tn[0] for tn in self.table_names)\n",
    "    def getHandledNames(self,):\n",
    "        return tuple(self.RE_patterns.keys())\n",
    "    def getRawRecords(self, ec, table_name):\n",
    "        return self._pages[ec][\"raw_records\"][table_name]\n",
    "    def getHandledRecords(self, ec, table_name):\n",
    "        return self._pages[ec][\"handled_records\"][table_name]\n",
    "\n",
    "    ### do the job.\n",
    "    def register(self, txtfile = paths[\"file\"], namefile = paths[\"NAME\"]):\n",
    "        with open(txtfile, 'r') as f:\n",
    "            self.content = [ line for line in f.readlines()] # len(self.content) = 4604276\n",
    "        with open(namefile, 'r') as f:\n",
    "            self.table_names = eval(f.read()) # len(self.table_names) = 44\n",
    "    def parse(self, ):\n",
    "        self.genRecords()\n",
    "        self.handleRecords()\n",
    "\n",
    "    def addPage(self, ec):\n",
    "        \"\"\"\n",
    "        use defaultdict(list) as the kernel.\n",
    "        \"\"\"\n",
    "        self._pages[ec] = {\n",
    "            \"raw_records\": defaultdict(list),\n",
    "            \"handled_records\": defaultdict(list),\n",
    "        }\n",
    "    def addRawRecord(self, ec, table_name, record):\n",
    "        self._pages[ec][\"raw_records\"][table_name].append(record)\n",
    "    def addHandledRecord(self, ec, table_name, record):\n",
    "        self._pages[ec][\"handled_records\"][table_name].append(record)\n",
    "\n",
    "    def genRecords(self, ):\n",
    "        \"\"\"\n",
    "        Model the file as a Finite State Machine.\n",
    "        \"\"\"\n",
    "        states = ['BEGIN', 'IN_PAGE', 'IN_TABLE']\n",
    "        state = states[0]\n",
    "        ec = ''\n",
    "        table_name = ''\n",
    "        abbre = ''\n",
    "        record = ''\n",
    "        for line in self.content:\n",
    "            if state == states[0]: # BEGIN \n",
    "                if line.startswith('ID\\t'):\n",
    "                    ec = line[3:-1]\n",
    "                    self.addPage(ec)\n",
    "                    state = states[1]\n",
    "            elif state == states[1]: # IN_PAGE\n",
    "                if line.startswith('\\n') or line.startswith('*'):\n",
    "                    pass\n",
    "                elif line.startswith('///'):\n",
    "                    ec = ''\n",
    "                    state = states[0]\n",
    "                else:\n",
    "                    for tn in self.table_names:\n",
    "                        if line.startswith(tn[0]):\n",
    "                            table_name = tn[0]\n",
    "                            abbre = tn[1]\n",
    "                            state = states[2]\n",
    "                            break\n",
    "            elif state == states[2]: # IN_TABLE\n",
    "                if line.startswith(abbre):\n",
    "                    if record:\n",
    "                        self.addRawRecord(ec, table_name, record)\n",
    "                    record = ' '.join(line.split('\\t')[1:])[:-1]\n",
    "                elif line.startswith('\\n'):\n",
    "                    if record:\n",
    "                        self.addRawRecord(ec, table_name, record)\n",
    "                    table_name = ''\n",
    "                    abbre = ''\n",
    "                    record = ''\n",
    "                    state = states[1]\n",
    "                else:\n",
    "                    record = record + ' ' + ' '.join(line.split('\\t')[1:])[:-1]\n",
    "\n",
    "    def handleRecords(self, ):\n",
    "        \"\"\"\n",
    "        Process records using Regular Expressions\n",
    "        \"\"\"\n",
    "        for ec in self._pages.keys():\n",
    "            for table_name, RE in self.RE_patterns.items():\n",
    "                for record in self.getRawRecords(ec, table_name):\n",
    "                    re_result = re.match(RE, record)\n",
    "                    if re_result:\n",
    "                        self.addHandledRecord(ec, table_name, re.match(RE, record).groups())\n",
    "                    elif table_name == 'SYNONYMS':\n",
    "                        if record.endswith('>') and len(record.split('<')) == 2:\n",
    "                            content, ref = record.split('<')\n",
    "                            self.addHandledRecord(ec, table_name, (None, content, None, None, ref[:-1]))\n",
    "                        else:\n",
    "                            self.addHandledRecord(ec, table_name, (None, record, None, None, None))\n",
    "                    # else:\n",
    "                    #     ERROR_RECORDS.append((ec, table_name, record))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_RECORDS = []\n",
    "bp = brenda_parser(txtfile = paths[\"file\"], namefile = paths[\"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for records in ERROR_RECORDS:\n",
    "    print(records)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
